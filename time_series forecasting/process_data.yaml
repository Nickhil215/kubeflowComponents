name: Preprocess Component JSON Data
description: Loads component metrics from a JSON file, encodes component IDs, and normalizes values per component using MinMaxScaler.

inputs:
- {name: json_data, type: string}
- {name: encoder_path, type: string}
- {name: scalers_path, type: string}

outputs:
- {name: json_data}
- {name: encoder_path}
- {name: scalers_path}

implementation:
  container:
    image: python:3.8
    command:
      - sh
      - -c
      - |
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet pandas scikit-learn joblib || \
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet pandas scikit-learn joblib --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import pandas as pd
        from sklearn.preprocessing import LabelEncoder, MinMaxScaler
        import joblib
        import argparse
        import os
        import json

        def preprocess(df):
            encoder = LabelEncoder()
            df['component_id'] = encoder.fit_transform(df['component'])
            df['value_norm'] = 0.0
            scalers = {}

            for component in df['component'].unique():
                mask = df['component'] == component
                scaler = MinMaxScaler()
                df.loc[mask, 'value_norm'] = scaler.fit_transform(df.loc[mask][['value']])
                scalers[component] = scaler

            return df, encoder, scalers

        parser = argparse.ArgumentParser()
        parser.add_argument("--json_data", type=str, required=True)
        parser.add_argument("--encoder_path", type=str, required=True)
        parser.add_argument("--scalers_path", type=str, required=True)
        args = parser.parse_args()

        # Load JSON data
        with open(args.json_data, "r") as f:
            raw_data = json.load(f)

        df = pd.DataFrame(raw_data)
        df_out, encoder, scalers = preprocess(df)

        # Save output back to JSON
        with open(args.json_data, "w") as f:
            json.dump(df_out.to_dict(orient="records"), f, indent=2)

        # Save models
        joblib.dump(encoder, args.encoder_path)
        joblib.dump(scalers, args.scalers_path)

        print(f"Saved normalized JSON data to {args.json_data}")
    args:
      - --json_data
      - {outputPath: json_data}
      - --encoder_path
      - {outputPath: encoder_path}
      - --scalers_path
      - {outputPath: scalers_path}
