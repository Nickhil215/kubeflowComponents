name: Data Loader
description: Splits input data into training and validation sets with configurable validation size
inputs:
  - name: data_source
    type: CSV
    description: 'Input CSV file path containing the dataset to be split'
  - name: val_size
    type: Float
    default: '0.2'
    description: 'Validation set size as a fraction between 0 and 1'
outputs:
  - name: train_data
    type: String
    description: 'Training dataset in CSV format'
  - name: val_data
    type: String
    description: 'Validation dataset in CSV format'
  - name: metadata
    type: JsonObject
    description: 'Metadata containing dataset statistics, features, and shape information'
implementation:
  container:
    image: nikhilv215/data_loader:1
    command: [
      "python3",
      "-m",
      "data_loader",
      "--data-source",
      {inputPath: data_source},
      "--val-size",
      {inputValue: val_size},
      "--output-paths",
      {outputPath: train_data},
      {outputPath: val_data},
      {outputPath: metadata}
    ]
metadata:
  annotations:
    author: Your Name
    framework: Pandas & Scikit-learn
    version: '1.0.0'
