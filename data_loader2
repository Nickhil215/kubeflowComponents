name: Data Loader
description: Splits input data into training and validation sets with configurable validation size

inputs:
  - {name: data_input, type: csv, description: 'Input CSV file path or direct CSV content'}
  - {name: val_size, type: Float, default: '0.2', description: 'Validation set size (between 0 and 1)'}

outputs:
  - {name: train_data, type: String, description: 'Training data in CSV format'}
  - {name: val_data, type: String, description: 'Validation data in CSV format'}
  - {name: metadata, type: JsonObject, description: 'Metadata including dataset sizes and file paths'}

implementation:
  container:
    image: nikhilv215/data_loader:1
    command: [
      python3,
      -m,
      dl_f.py,
      --data-input,
      {inputPath: data_input},
      --val-size,
      {inputValue: val_size},
      --output-paths,
      {outputPath: train_data},
      {outputPath: val_data},
      {outputPath: metadata}
    ]

metadata:
  annotations:
    author: Your Name
    framework: Pandas & Scikit-learn
    version: '1.0.0'
